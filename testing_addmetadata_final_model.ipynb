{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcb7g+jnYokToO/cM/wnS+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwangzie/Detect-Corner-Mark-on-Device-and-Image-Quality/blob/main/testing_addmetadata_final_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jFftpKVSUgA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4idYulcNHTdO"
      },
      "outputs": [],
      "source": [
        "tflite_model_file = pathlib.Path('/content/finalmodelup.tflite')\n",
        "# tflite_model_file.write_bytes(tflite_model_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgGvp2yBG25Q"
      },
      "source": [
        "## Initialize the TFLite interpreter to try it out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOt94wIWF8m7"
      },
      "outputs": [],
      "source": [
        "# Load TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model_file.read_bytes())\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGYkEK08F8qK"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create an upload button\n",
        "upload_button = widgets.FileUpload(accept='image/*', multiple=True)  # Allow multiple files\n",
        "display(upload_button)\n",
        "\n",
        "def predict_uploaded_image(interpreter, input_details, output_details, uploaded_file):\n",
        "  \"\"\"Predicts the class of an uploaded image using both TensorFlow and TensorFlow Lite.\"\"\"\n",
        "\n",
        "  # Preprocess the image\n",
        "  img = Image.open(io.BytesIO(uploaded_file['content']))\n",
        "  img = img.resize((224, 224))\n",
        "  img = img.convert('RGB')\n",
        "  img_array = np.array(img) / 255.0\n",
        "  img_array = np.expand_dims(img_array, axis=0).astype(np.float32)\n",
        "\n",
        "  # TensorFlow Lite prediction\n",
        "  interpreter.set_tensor(input_details[0]['index'], img_array)\n",
        "  interpreter.invoke()\n",
        "  tflite_results = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "  # Display results and image in a subplot\n",
        "  fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
        "  ax.imshow(img)\n",
        "  ax.set_title(f\"TF Lite: {tflite_results[0][0]}\")\n",
        "  ax.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def on_upload_change(change):\n",
        "  \"\"\"Handles the upload button change event.\"\"\"\n",
        "  for uploaded_file in upload_button.value.values():\n",
        "    predict_uploaded_image(interpreter, input_details, output_details, uploaded_file)\n",
        "\n",
        "# Observe the upload button for changes\n",
        "upload_button.observe(on_upload_change, names='value')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tflite-support-nightly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tzl46YrcUKTV",
        "outputId": "7f97b630-a6a7-4a61-aaf1-d6540dc53fe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tflite-support-nightly in /usr/local/lib/python3.10/dist-packages (0.4.4.dev20230716)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tflite-support-nightly) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from tflite-support-nightly) (1.26.4)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tflite-support-nightly) (24.3.25)\n",
            "Requirement already satisfied: protobuf<4,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from tflite-support-nightly) (3.20.3)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from tflite-support-nightly) (0.5.1)\n",
            "Requirement already satisfied: pybind11>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from tflite-support-nightly) (2.13.6)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->tflite-support-nightly) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->tflite-support-nightly) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tflite_support.metadata_writers import image_classifier\n",
        "from tflite_support.metadata_writers import writer_utils"
      ],
      "metadata": {
        "id": "ET2AQix6Ttze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ImageClassifierWriter = image_classifier.MetadataWriter\n",
        "_MODEL_PATH = \"/content/finalmodelup.tflite\"\n",
        "# Task Library expects label files that are in the same format as the one below.\n",
        "_LABEL_FILE = \"label.txt\"\n",
        "_SAVE_TO_PATH = \"final_model_metadata.tflite\"\n",
        "# Normalization parameters is required when reprocessing the image. It is\n",
        "# optional if the image pixel values are in range of [0, 255] and the input\n",
        "# tensor is quantized to uint8. See the introduction for normalization and\n",
        "# quantization parameters below for more details.\n",
        "# https://www.tensorflow.org/lite/models/convert/metadata#normalization_and_quantization_parameters)\n",
        "_INPUT_NORM_MEAN = 127.5\n",
        "_INPUT_NORM_STD = 127.5\n",
        "\n",
        "# Create the metadata writer.\n",
        "writer = ImageClassifierWriter.create_for_inference(\n",
        "    writer_utils.load_file(_MODEL_PATH), [_INPUT_NORM_MEAN], [_INPUT_NORM_STD],\n",
        "    [_LABEL_FILE])\n",
        "\n",
        "# Verify the metadata generated by metadata writer.\n",
        "print(writer.get_metadata_json())\n",
        "\n",
        "# Populate the metadata into the model.\n",
        "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icc4998cT0TP",
        "outputId": "aab5a448-2ef7-4b68-c5a2-36dbd9b3c400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\": \"ImageClassifier\",\n",
            "  \"description\": \"Identify the most prominent object in the image from a known set of categories.\",\n",
            "  \"subgraph_metadata\": [\n",
            "    {\n",
            "      \"input_tensor_metadata\": [\n",
            "        {\n",
            "          \"name\": \"image\",\n",
            "          \"description\": \"Input image to be classified.\",\n",
            "          \"content\": {\n",
            "            \"content_properties_type\": \"ImageProperties\",\n",
            "            \"content_properties\": {\n",
            "              \"color_space\": \"RGB\"\n",
            "            }\n",
            "          },\n",
            "          \"process_units\": [\n",
            "            {\n",
            "              \"options_type\": \"NormalizationOptions\",\n",
            "              \"options\": {\n",
            "                \"mean\": [\n",
            "                  127.5\n",
            "                ],\n",
            "                \"std\": [\n",
            "                  127.5\n",
            "                ]\n",
            "              }\n",
            "            }\n",
            "          ],\n",
            "          \"stats\": {\n",
            "            \"max\": [\n",
            "              1.0\n",
            "            ],\n",
            "            \"min\": [\n",
            "              -1.0\n",
            "            ]\n",
            "          }\n",
            "        }\n",
            "      ],\n",
            "      \"output_tensor_metadata\": [\n",
            "        {\n",
            "          \"name\": \"probability\",\n",
            "          \"description\": \"Probabilities of the labels respectively.\",\n",
            "          \"content\": {\n",
            "            \"content_properties_type\": \"FeatureProperties\",\n",
            "            \"content_properties\": {\n",
            "            }\n",
            "          },\n",
            "          \"stats\": {\n",
            "            \"max\": [\n",
            "              1.0\n",
            "            ],\n",
            "            \"min\": [\n",
            "              0.0\n",
            "            ]\n",
            "          },\n",
            "          \"associated_files\": [\n",
            "            {\n",
            "              \"name\": \"label.txt\",\n",
            "              \"description\": \"Labels for categories that the model can recognize.\",\n",
            "              \"type\": \"TENSOR_AXIS_LABELS\"\n",
            "            }\n",
            "          ]\n",
            "        }\n",
            "      ]\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n"
          ]
        }
      ]
    }
  ]
}